{"cells":[{"cell_type":"markdown","metadata":{"id":"-mEz-rZSMJnf"},"source":["# ⏰ **AN2DL 2022 - CHALLENGE 2** ⏰"]},{"cell_type":"markdown","source":["# **Project utilities:**\n","\n","\n","*   Google Drive connection\n","*   Installation of TSAug for Sequences augmentation\n","*   Metadata, variables and imports\n","*   Seed setting\n","*   Callback and folders creation\n","\n"],"metadata":{"id":"jobJBzcdi-nF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"P4TpIQomLi3j"},"outputs":[],"source":["#@title **Loading data from gdrive to memory**\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/ANNDL_Challenge_2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PhRLfE6MMccg"},"outputs":[],"source":["!pip install tsaug"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QPm9Hgv-MjSa","cellView":"form"},"outputs":[],"source":["#@title **Imports**\n","import warnings\n","import logging\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from keras import Sequential\n","from keras.models import Model\n","from keras.layers import *\n","from keras.optimizers import Adam\n","import numpy as np\n","import os\n","import random\n","import pandas as pd\n","import scipy\n","from datetime import datetime\n","from google.colab import files\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n","from sklearn.preprocessing import LabelBinarizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IbejbyEEMjYo","cellView":"form"},"outputs":[],"source":["#@title **Metadata and variables**\n","\n","tfk = tf.keras\n","tfkl = tf.keras.layers\n","\n","seed = 42\n","test_percentage = 0.1\n","nclasses = 12\n","\n","kfold = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RU0GNn5gM49u","cellView":"form"},"outputs":[],"source":["#@title **Setting seed and/or suppressing warnings**\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=Warning)\n","tf.get_logger().setLevel('INFO')\n","tf.autograph.set_verbosity(0)\n","\n","tf.get_logger().setLevel(logging.ERROR)\n","tf.get_logger().setLevel('ERROR')\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","\n","# Setting random seed for reproducibility\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Vh1ISn2M7jL","cellView":"form"},"outputs":[],"source":["#@title **Utility function to create folders and callbacks for training**\n","def create_folders_and_callbacks(model_name):\n","\n","  exps_dir = os.path.join('trained_models')\n","  if not os.path.exists(exps_dir):\n","      os.makedirs(exps_dir)\n","\n","  now = datetime.now().strftime('%m-%d_%H-%M-%S')\n","\n","  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n","  if not os.path.exists(exp_dir):\n","      os.makedirs(exp_dir)\n","      \n","  callbacks = []\n","\n","  # Model checkpoint\n","  # ----------------\n","  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n","  if not os.path.exists(ckpt_dir):\n","      os.makedirs(ckpt_dir)\n","\n","  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(\n","                                                     filepath=ckpt_dir + '/cp-{val_accuracy:.2f}-{epoch:02d}.ckpt', # Checkpoint is saved with validation accuracy in the filename\n","                                                     # filepath=ckpt_dir + '/cp-{epoch:02d}.ckpt',\n","                                                     monitor='val_accuracy', \n","                                                     # save_freq='epoch',\n","                                                     # period=10,\n","                                                     save_weights_only=True, # True to save only weights\n","                                                     save_best_only=True, # True to save only the best epoch \n","                                                     initial_value_threshold=0.65\n","                                                     ) # Model is saved only if val_accuracy > initial_value_threshold\n","\n","  callbacks.append(ckpt_callback)\n","\n","\n","  # Visualize Learning on Tensorboard\n","  # ---------------------------------\n","  tb_dir = os.path.join(exp_dir, 'tb_logs')\n","  if not os.path.exists(tb_dir):\n","      os.makedirs(tb_dir)\n","      \n","  # By default shows losses and metrics for both training and validation\n","  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir, \n","                                               profile_batch=0,\n","                                               histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n","  callbacks.append(tb_callback)\n","\n","  # Early Stopping\n","  # --------------\n","  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n","  callbacks.append(es_callback)\n","\n","  return callbacks, exp_dir"]},{"cell_type":"markdown","source":["# **Data preprocessing:**\n","*   Oversampling\n","*   Undersampling\n","*   Augmentation \n","*   Creation of sliding windows with random validation-test sampling with possible integrated augmentation and oversampling"],"metadata":{"id":"_fJZedfww8cn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kodf5gei-24a","cellView":"form"},"outputs":[],"source":["#@title OneHot-to-categorical translation function\n","\n","def to_numerical(y):\n","  return np.argmax(y, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5wP8I94sf-zB","cellView":"form"},"outputs":[],"source":["#@title Utility method to evaluate classes' weights\n","\n","def get_num_elements(y):\n","    elements = np.zeros(nclasses)\n","\n","    for i in range(nclasses):\n","         elements[i] = sum(1 for seq in range(y.shape[0]) if y[seq] == i)\n","    \n","    return elements\n","\n","\n","def get_class_weights(y, for_fit=True):\n","\n","  num_samples = y.shape[0]\n","\n","  elements = np.zeros(nclasses)\n","  weights = np.zeros(nclasses)\n","  elements = get_num_elements(y)\n","\n","  for i in range(nclasses):\n","      weights[i] = (1 / elements[i]) * (num_samples / float(nclasses))\n","\n","\n","  class_weight = {0: weights[0], 1: weights[1], 2: weights[2], 3: weights[3],\n","                  4: weights[4], 5: weights[5], 6: weights[6], 7: weights[7], \n","                  8: weights[8], 9: weights[9], 10: weights[10], 11: weights[11]}\n","  print(\"Samples count: \", elements)\n","  print(\"Class weights: \", weights)\n","\n","  if not for_fit:\n","    return weights\n","\n","  return class_weight"]},{"cell_type":"code","source":["#@title Sort-back function\n","\n","# This function gets unsorted training set and the complete one, and returns the sorted training set together with a set of indices that\n","# represent where some samples have been taken for validation or test (where the sequences have been broken).\n","# useful to reconstruct the ordered training set.\n","# needed to build sliding windows, because stratified sampling for val/test ruins the original order.\n","\n","def sort_back(X_to_sort, y_to_sort, X, y):\n","\n","  X_sorted = np.empty(X_to_sort.shape)\n","  y_sorted = np.empty(y_to_sort.shape)\n","  holes = [0]\n","\n","  reordering_indices = []\n","\n","  for r, row in enumerate(X_to_sort):\n","    reordering_indices.append(np.where(np.all(row == X, axis=1))[0][0])\n","\n","  # print(\"reordering indices: \", reordering_indices)\n","\n","  last_min = 0\n","  for r, row in enumerate(X_to_sort):\n","    min = np.min(reordering_indices)\n","    if r != 0 and r != X_to_sort.shape[0] and min > last_min + 1:\n","      holes.append(r-1)\n","    last_min = min\n","    reordering_indices.remove(min)\n","    X_sorted[r] = X[min]\n","    y_sorted[r] = y[min]\n","  \n","  holes.append(X_to_sort.shape[0])\n","\n","  # print(\"Holes introduced randomly sampling this class: \", holes)\n","\n","  return X_sorted, y_sorted, np.array(holes)\n"],"metadata":{"id":"wwP_41q5aFav","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cQj3sibGFo15","cellView":"form"},"outputs":[],"source":["#@title Undersampling/Oversampling parameters generator\n","\n","def get_class_prob(y):\n","\n","    if y.ndim == 2:\n","      y = to_numerical(y)\n","\n","    num_samples = y.shape[0]\n","\n","    elements = np.zeros(nclasses)\n","    probs = np.zeros(nclasses)\n","\n","    for i in range(nclasses):\n","         elements[i] = sum(1 for seq in range(y.shape[0]) if y[seq] == i)\n","         probs[i] = elements[i] / float(num_samples)\n","    \n","    return probs\n","\n","# sampling parameters use it wisely \n","oversampling_coef = 0.9 # if equal to 0 then oversample_classes() always returns 1\n","undersampling_coef = 2.0 # if equal to 0 then undersampling_filter() always returns True\n","\n","def oversample_classes(y_train, nclasses=nclasses):\n","    \"\"\"\n","    Returns the number of copies of given example\n","    \"\"\"\n","\n","    class_prob = get_class_prob(y_train)\n","    class_target_prob = 1 / nclasses\n","    prob_ratio = tf.cast(class_target_prob/class_prob, dtype=tf.float32)\n","    # soften ratio is oversampling_coef==0 we recover original distribution\n","    prob_ratio = prob_ratio ** oversampling_coef \n","    # for classes with probability higher than class_target_prob we\n","    # want to return 1\n","    prob_ratio = tf.maximum(prob_ratio, 1) \n","    # for low probability classes this number will be very large\n","    repeat_count = tf.floor(prob_ratio)\n","    # prob_ratio can be e.g 1.9 which means that there is still 90%\n","    # of change that we should return 2 instead of 1\n","    repeat_residual = prob_ratio - repeat_count # a number between 0-1\n","    residual_acceptance = tf.less_equal(\n","                        tf.random.uniform([], dtype=tf.float32), repeat_residual\n","    )\n","\n","    residual_acceptance = tf.cast(residual_acceptance, tf.int64)\n","    repeat_count = tf.cast(repeat_count, dtype=tf.int64)\n","    return repeat_count + residual_acceptance\n","\n","def undersampling_filter(y_train, nclasses=nclasses):\n","    \"\"\"\n","    Computes if given example is rejected or not.\n","    \"\"\"\n","    class_prob = get_class_prob(y_train)\n","    class_target_prob = 1 / nclasses\n","    prob_ratio = tf.cast(class_target_prob/class_prob, dtype=tf.float32)\n","    prob_ratio = prob_ratio ** undersampling_coef\n","    prob_ratio = tf.minimum(prob_ratio, 1.0)\n","\n","    acceptance = tf.less_equal(tf.random.uniform([], dtype=tf.float32), prob_ratio)\n","    # predicate must return a scalar boolean tensor\n","    num_deletions = np.array([(1 - ratio) for ratio in prob_ratio])\n","    return num_deletions"]},{"cell_type":"code","source":["#@title Undersampling function\n","\n","def undersample(X, y, classes_to_undersample):\n","  filter = undersampling_filter(y)\n","  X_new = []\n","  y_new = []\n","\n","  if y.ndim == 2:\n","    y_numerical = to_numerical(y)\n","\n","  for i in range(X.shape[0]):\n","    if y_numerical[i] not in classes_to_undersample or (y_numerical[i] in classes_to_undersample and np.random.random() > filter[y_numerical[i]]/2):\n","      X_new.append(X[i])\n","      y_new.append(y[i])\n","\n","  return np.array(X_new), np.array(y_new) \n"],"metadata":{"cellView":"form","id":"UwsHLRIWOb7S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Oversampling function\n","def oversample(X, y_categorical):\n","  y_numerical = to_numerical(y_categorical)\n","\n","  num_of_copies = oversample_classes(y_numerical, 4)\n","\n","  X_new = []\n","  y_new = []\n","  \n","  for i in range(X.shape[0]):\n","    for _ in range(num_of_copies[y_numerical[i]]):\n","      X_new.append(X[i])\n","      y_new.append(y_categorical[i])\n","\n","  return np.array(X_new), np.array(y_new)"],"metadata":{"cellView":"form","id":"szltS1CjMJe6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Plot of effect of Over/Undersampling on samples distributions \n","\n","X = np.load(\"training_dataset_homework2/x_train.npy\")\n","y = np.load(\"training_dataset_homework2/y_train.npy\")\n","\n","# putting labels from Categorical to One-Hot\n","label_as_binary = LabelBinarizer()\n","y = label_as_binary.fit_transform(y)\n","\n","X_os, y_os = oversample(X, y)\n","X_us, y_us = undersample(X, y, [i for i in range(nclasses)])\n","\n","elements_original = get_num_elements(y=to_numerical(y))\n","elements_os = get_num_elements(y=to_numerical(y_os))\n","elements_us = get_num_elements(y=to_numerical(y_us))\n","\n","x_axis = [\"Wish\",\n","    \"Another\",\n","    \"Comfortably\",\n","    \"Money\",\n","    \"Breathe\",\n","    \"Time\",\n","    \"Brain\",\n","    \"Echoes\",\n","    \"Wearing\",\n","    \"Sorrow\",\n","    \"Hey\",\n","    \"Shine\"]\n","\n","fig, axs = plt.subplots(1, 3, figsize=(20, 6))\n","\n","# We can set the number of bins with the *bins* keyword argument.\n","axs[0].set_ylim([0, 800])\n","axs[0].tick_params(labelrotation=90)\n","axs[0].set_title(\"Original distribution\")\n","axs[0].bar(x_axis, elements_original, align=\"edge\")\n","axs[1].set_ylim([0, 800])\n","axs[1].tick_params(labelrotation=90)\n","axs[1].set_title(\"Distribution after Oversampling\")\n","axs[1].bar(x_axis, elements_os)\n","axs[2].set_ylim([0, 800])\n","axs[2].tick_params(labelrotation=90)\n","axs[2].set_title(\"Distribution after Undersampling\")\n","axs[2].bar(x_axis, elements_us)\n","\n","plt.show()\n"],"metadata":{"cellView":"form","id":"1P-xSequRFwv"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MzGS9zcMCWrS"},"outputs":[],"source":["#@title Augmentation function\n","\n","import tsaug\n","from tsaug import AddNoise, Convolve, Crop, Drift, Pool, Quantize, Resize, Reverse, TimeWarp\n","\n","heavy_augmenter = (\n","                tsaug.AddNoise(scale=(0.5, 0.8)) @ 0.1\n","                # + tsaug.Convolve(window=\"hamming\", size=12) @ 0.2\n","                # + tsaug.Drift(max_drift=(0, 0.02)) @ 0.2\n","                + tsaug.TimeWarp(50) @ 0.3\n","                + tsaug.Pool(size=4) @ 0.3\n","              )\n","light_augmenter = (\n","                tsaug.AddNoise(scale=(0.05, 0.2)) @ 0.5\n","                # + tsaug.Convolve(window=\"hamming\", size=12) @ 0.2\n","                # + tsaug.Drift(max_drift=(0, 0.02)) @ 0.2\n","                + tsaug.TimeWarp(2) @ 0.3\n","                + tsaug.Pool(size=4) @ 0.3\n","              )\n","\n","def augment_dataset(X, y):\n","  y_numerical = to_numerical(y)\n","  X_aug = []\n","  for i in range(X.shape[0]):\n","    print(\"Augmenting element \" + str(i))\n","    if y_numerical[i] in [4, 5, 7, 11]:\n","      augmenter = light_augmenter\n","    else:\n","      augmenter = heavy_augmenter\n","    aug_sequence = np.empty(X[i].shape)\n","    aug_sequence = augmenter.augment(X[i])\n","    X_aug = append_sequence(X_aug, aug_sequence)\n","\n","  X_aug = np.array(X_aug)\n","\n","  return X_aug\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bFQ1gI9l5lTE"},"outputs":[],"source":["#@title Sliding Windows with augmentation and oversampling\n","\n","def permute(X, y):\n","    permutation = np.random.permutation(X.shape[0])\n","    X_permuted = X[permutation]\n","    y_permuted = y[permutation]\n","\n","    return X_permuted, y_permuted\n","\n","\n","def append_sequence(X, seq):\n","  if len(X)==0:\n","    X_new = seq\n","  else:\n","    X_new = np.r_[X, seq]\n","\n","  return X_new\n","\n","import tsaug\n","from tsaug import AddNoise, Convolve, Crop, Drift, Pool, Quantize, Resize, Reverse, TimeWarp\n","\n","heavy_augmenter = (\n","                tsaug.AddNoise(scale=(0.5, 0.8)) @ 0.1\n","                # + tsaug.Convolve(window=\"hamming\", size=12) @ 0.2\n","                # + tsaug.Drift(max_drift=(0, 0.02)) @ 0.2\n","                + tsaug.TimeWarp(50) @ 0.3\n","                + tsaug.Pool(size=4) @ 0.3\n","              )\n","light_augmenter = (\n","                tsaug.AddNoise(scale=(0.05, 0.2)) @ 0.5\n","                # + tsaug.Convolve(window=\"hamming\", size=12) @ 0.2\n","                # + tsaug.Drift(max_drift=(0, 0.02)) @ 0.2\n","                + tsaug.TimeWarp(2) @ 0.3\n","                + tsaug.Pool(size=4) @ 0.3\n","              )\n","\n","def perform_sliding_window(X, y, kfold=False, stride=1, oversample=False, augment=False):\n","\n","    y_numerical = to_numerical(y)\n","\n","    num_of_copies = oversample_classes(y_numerical)\n","\n","    # unwrapping sequences to a single long sequence\n","    sliding_windows = []\n","    y_of_windows = []\n","    X_test_global = []\n","    y_test_global = []\n","\n","    if not kfold:\n","        X_val_global = []\n","        y_val_global = []\n","\n","    for i in range(nclasses):\n","        print(\"windowing and oversampling class %d ...\" %i)\n","\n","        X_train, X_test, y_train, y_test = train_test_split(X[to_numerical(y) == i], y[to_numerical(y) == i], test_size=test_percentage, shuffle=True, stratify=to_numerical(y[to_numerical(y) == i]), random_state=seed)\n","\n","        # for each class, we keep 10% for val, while the rest is used to create sliding windows\n","        if not kfold:\n","            X_train, X_val, y_train, y_val = train_test_split(X_train[to_numerical(y_train) == i], y_train[to_numerical(y_train) == i], test_size=test_percentage, shuffle=True, stratify=to_numerical(y_train[to_numerical(y_train) == i]), random_state=seed)\n","\n","            # holes contains the indices of all the \"holes\" introduced to the sequence by Splitting\n","            # (needed to avoid making sliding windows that \"jump over separated zones of the sequences\")\n","            X_train, y_train, holes = sort_back(X_train, y_train, X, y)\n","\n","            X_val_global = append_sequence(X_val_global, X_val)\n","            y_val_global = append_sequence(y_val_global, y_val)\n","        \n","        X_test_global = append_sequence(X_test_global, X_test)\n","        y_test_global = append_sequence(y_test_global, y_test)\n","\n","        class_unwrapped = []\n","        for seq in X_train:\n","            class_unwrapped = append_sequence(class_unwrapped, seq)\n","            \n","        class_unwrapped = np.array(class_unwrapped)\n","\n","        if i in [4, 5, 7, 11]:\n","          augmenter = light_augmenter\n","        else:\n","          augmenter = heavy_augmenter\n","\n","        # perform sliding windows (skipping holes)\n","        for h in range(holes.shape[0]-1):\n","          for j in range(holes[h]*36, int((holes[h+1]*36-36) / stride)):\n","            \n","            if augment and not oversample:\n","              window = augmenter.augment(class_unwrapped[stride*j:stride*j+36, :])\n","            else:\n","              window = class_unwrapped[stride*j:stride*j+36, :]\n","            sliding_windows.append(window)\n","            y_of_windows.append(i)\n","\n","            if oversample:\n","              for _ in range(num_of_copies[i]-1):\n","                  if augment:\n","                    window = augmenter.augment(class_unwrapped[stride*j:stride*j+36, :])\n","                  else:\n","                    window = class_unwrapped[stride*j:stride*j+36, :]\n","                  sliding_windows.append(window)\n","                  y_of_windows.append(i)\n","                \n","\n","    # re-formatting labels to OneHot to make them ready-to-use\n","    label_as_binary = LabelBinarizer()\n","    y_of_windows = label_as_binary.fit_transform(y_of_windows)\n","\n","\n","    X_test_global, y_test_global = permute(np.array(X_test_global), np.array(y_test_global))\n","    X_train_global, y_train_global = permute(np.array(sliding_windows), np.array(y_of_windows))\n","\n","    if not kfold:\n","        X_val_global, y_val_global = permute(np.array(X_val_global), np.array(y_val_global))\n","        return X_train_global, y_train_global, X_val_global, y_val_global, X_test_global, y_test_global\n","    \n","    else:\n","        return X_train_global, y_train_global, X_test_global, y_test_global\n","\n","\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ylh9kM6gqsdG","cellView":"form"},"outputs":[],"source":["#@title Scaling function (manual RobustScaler)\n","\n","def scale(x):\n","  median_list = []\n","  iq_list = []\n","\n","  x_s = []\n","  x_norm = x.copy()\n","\n","  for m in range(x.shape[2]):\n","      x_reshaped = np.reshape(x[:,:,m], (x.shape[0]*x.shape[1]))\n","      median = np.median(x_reshaped)\n","      median_list.append(median)\n","\n","      perc75 = np.percentile(x_reshaped, 75)\n","      perc25 = np.percentile(x_reshaped, 25)\n","\n","      iq = perc75 - perc25\n","      iq_list.append(iq)\n","\n","      x_s.append((x_reshaped - median) / iq)\n","      x_norm[:, :, m] = (x[:,:,m] - median) / iq\n","        \n","  return x_norm, median_list, iq_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K0X4kuwkY-GD"},"outputs":[],"source":["#@title Train/val/test split\n","\n","X = np.load(\"training_dataset_homework2/x_train.npy\")\n","y = np.load(\"training_dataset_homework2/y_train.npy\")\n","\n","# robust scaling and saving medians and inter-quantiles\n","# X, y = undersample(X, y, [3,9])\n","\n","X, median, iq = scale(X)\n","np.save('median', np.array(median))\n","np.save('iq', np.array(iq))\n","\n","y_numerical = y.copy()\n","\n","# putting labels from Categorical to One-Hot\n","label_as_binary = LabelBinarizer()\n","y = label_as_binary.fit_transform(y)\n","\n","print(\"Before windowing and oversampling: \")\n","get_class_weights(to_numerical(y))\n","\n","X_train, y_train, X_val, y_val, X_test, y_test = perform_sliding_window(X, y, stride=1, oversample=False, augment=True)\n","\n","print(\"After windowing and oversampling: \")\n","get_class_weights(to_numerical(y_train))\n","\n","y_numerical = to_numerical(y_train)\n","\n","X_train.shape, y_train.shape, X_val.shape, y_val.shape"]},{"cell_type":"markdown","source":["# **Models:**\n","*  Vanilla LSTM\n","*  Bidirectional LSTM\n","*  Custom 1DConv model using LayerNormalization\n","*  Transformers\n","*  ResNet"],"metadata":{"id":"01Da5EV2vw8u"}},{"cell_type":"code","execution_count":34,"metadata":{"id":"rOD9bSIqbirT","executionInfo":{"status":"ok","timestamp":1671811657869,"user_tz":-60,"elapsed":262,"user":{"displayName":"Andrea Cerasani","userId":"02098686880230063779"}}},"outputs":[],"source":["#@title **Transformer Model**\n","\n","def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n","    # Attention and Normalization\n","    x = tfkl.MultiHeadAttention(\n","        key_dim=head_size, num_heads=num_heads, dropout=dropout\n","    )(inputs, inputs)\n","    x = tfkl.Dropout(dropout)(x)\n","    x = tfkl.LayerNormalization(epsilon=1e-6)(x)\n","    res = x + inputs\n","\n","    # Feed Forward Part\n","    x = tfkl.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n","    x = tfkl.Dropout(dropout)(x)\n","    x = tfkl.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n","    x = tfkl.LayerNormalization(epsilon=1e-6)(x)\n","    return x + res\n","\n","def build_model(\n","    input_shape,\n","    head_size,\n","    num_heads,\n","    ff_dim,\n","    num_transformer_blocks,\n","    mlp_units,\n","    dropout=0.0,\n","    mlp_dropout=0.0,\n","):\n","    inputs = tfk.Input(shape=input_shape)\n","    x = inputs\n","    for _ in range(num_transformer_blocks):\n","        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n","\n","    x = tfkl.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n","    for dim in mlp_units:\n","        x = tfkl.Dense(dim, activation=\"relu\")(x)\n","        x = tfkl.Dropout(mlp_dropout)(x)\n","    outputs = tfkl.Dense(nclasses, activation=\"softmax\")(x)\n","    return tfk.Model(inputs, outputs)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DENxF0hlKIOV","cellView":"form"},"outputs":[],"source":["#@title BiLSTM Model\n","def build_BiLSTM(input_shape, classes):\n","    # Build the neural network layer by layer\n","    input_layer = tfkl.Input(shape=input_shape, name='Input')\n","\n","    # Feature extractor\n","    bilstm = tfkl.Bidirectional(tfkl.LSTM(92, return_sequences=True))(input_layer)\n","    bilstm = tfkl.Bidirectional(tfkl.LSTM(92))(bilstm)\n","    dropout = tfkl.Dropout(0.5, seed=seed)(bilstm)\n","\n","    # Classifier\n","    # classifier = tfkl.Dense(60, activation='relu')(dropout)\n","    # classifier = tfkl.Dropout(0.3)(classifier)\n","    classifier = tfkl.Dense(128, activation='relu')(dropout)\n","    classifier = tfkl.Dropout(0.5)(classifier)\n","    output_layer = tfkl.Dense(classes, activation='softmax')(classifier)\n","\n","    # Connect input and output through the Model class\n","    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='BiLSTM')\n","\n","    # Compile the model\n","    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n","\n","    # Return the model\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZZ1oCQC2TFaL","cellView":"form"},"outputs":[],"source":["#@title Vanilla LSTM Model\n","\n","def build_LSTM(input_shape, classes):\n","    # Build the neural network layer by layer\n","    input_layer = tfkl.Input(shape=input_shape, name='Input')\n","\n","    # Feature extractor\n","    lstm = tfkl.LSTM(256, return_sequences=True)(input_layer)\n","    lstm = tfkl.LSTM(256)(lstm)\n","    dropout = tfkl.Dropout(.5, seed=seed)(lstm)\n","\n","    # Classifier\n","    classifier = tfkl.Dense(128, activation='relu')(dropout)\n","    output_layer = tfkl.Dense(classes, activation='softmax')(classifier)\n","\n","    # Connect input and output through the Model class\n","    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='VanillaLSTM')\n","\n","    # Compile the model\n","    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n","\n","    # Return the model\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EW0NYg42-2eI","cellView":"form"},"outputs":[],"source":["#@title ResNet Model\n","\n","def build_ResNet(input_shape, nb_classes):\n","        n_feature_maps = 16\n","\n","        keras = tfk\n","\n","        input_layer = keras.layers.Input(input_shape)\n","        # BLOCK 1\n","\n","        conv_x = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=8, padding='same')(input_layer)\n","        conv_x = keras.layers.BatchNormalization()(conv_x)\n","        conv_x = keras.layers.Activation('relu')(conv_x)\n","\n","        conv_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=5, padding='same')(conv_x)\n","        conv_y = keras.layers.BatchNormalization()(conv_y)\n","        conv_y = keras.layers.Activation('relu')(conv_y)\n","\n","        conv_z = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=3, padding='same')(conv_y)\n","        conv_z = keras.layers.BatchNormalization()(conv_z)\n","\n","        # expand channels for the sum\n","        shortcut_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=1, padding='same')(input_layer)\n","        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n","\n","        output_block_1 = keras.layers.add([shortcut_y, conv_z])\n","        output_block_1 = keras.layers.Activation('relu')(output_block_1)\n","\n","        # BLOCK 2\n","\n","        conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_1)\n","        conv_x = keras.layers.BatchNormalization()(conv_x)\n","        conv_x = keras.layers.Activation('relu')(conv_x)\n","\n","        conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n","        conv_y = keras.layers.BatchNormalization()(conv_y)\n","        conv_y = keras.layers.Activation('relu')(conv_y)\n","\n","        conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n","        conv_z = keras.layers.BatchNormalization()(conv_z)\n","\n","        # expand channels for the sum\n","        shortcut_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=1, padding='same')(output_block_1)\n","        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n","\n","        output_block_2 = keras.layers.add([shortcut_y, conv_z])\n","        output_block_2 = keras.layers.Activation('relu')(output_block_2)\n","\n","        # BLOCK 3\n","        \n","        conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_2)\n","        conv_x = keras.layers.BatchNormalization()(conv_x)\n","        conv_x = keras.layers.Activation('relu')(conv_x)\n","\n","        conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n","        conv_y = keras.layers.BatchNormalization()(conv_y)\n","        conv_y = keras.layers.Activation('relu')(conv_y)\n","\n","        conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n","        conv_z = keras.layers.BatchNormalization()(conv_z)\n","\n","        # no need to expand channels because they are equal\n","        shortcut_y = keras.layers.BatchNormalization()(output_block_2)\n","\n","        output_block_3 = keras.layers.add([shortcut_y, conv_z])\n","        output_block_3 = keras.layers.Activation('relu')(output_block_3)\n","        \n","\n","        # FINAL\n","\n","        gap_layer = keras.layers.GlobalAveragePooling1D()(output_block_3)\n","\n","        output_layer = keras.layers.Dense(nb_classes, activation='softmax')(gap_layer)\n","\n","        model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n","\n","        model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=keras.optimizers.Adam(1e-4),\n","                      metrics=['accuracy'])\n","\n","        return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2S8cMhfZf87M"},"outputs":[],"source":["#@title 1D Convolution Model\n","\n","def build_1DCNN(input_shape, classes):\n","    # Build the neural network layer by layer\n","    input_layer = tfkl.Input(shape=input_shape, name='Input')\n","\n","    # Feature extractor\n","    cnn = tfkl.Conv1D(256,3,padding='same',activation='relu')(input_layer)\n","    cnn = tfkl.LayerNormalization()(cnn)\n","    cnn = tfkl.MaxPooling1D()(cnn)\n","    cnn = tfkl.Conv1D(256,3,padding='same',activation='relu')(cnn)\n","    gap = tfkl.GlobalAveragePooling1D()(cnn)\n","    dropout = tfkl.Dropout(.6, seed=seed)(gap)\n","\n","    # Classifier\n","    classifier = tfkl.Dense(128, activation='relu')(dropout)\n","    classifier = tfkl.Dropout(.5)(classifier)\n","    output_layer = tfkl.Dense(classes, activation='softmax')(classifier)\n","\n","    # Connect input and output through the Model class\n","    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='1DCNN')\n","\n","    # Compile the model\n","    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n","\n","    # Return the model\n","    return model"]},{"cell_type":"markdown","source":["# Build and compile of models"],"metadata":{"id":"WuMeGtEvvpY4"}},{"cell_type":"code","execution_count":40,"metadata":{"id":"dQpmxwk5bZp-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671811695611,"user_tz":-60,"elapsed":1554,"user":{"displayName":"Andrea Cerasani","userId":"02098686880230063779"}},"outputId":"2757e8bb-51fc-4650-ca11-2ed906475ea3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_4\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_5 (InputLayer)           [(None, 36, 6)]      0           []                               \n","                                                                                                  \n"," multi_head_attention_8 (MultiH  (None, 36, 6)       110598      ['input_5[0][0]',                \n"," eadAttention)                                                    'input_5[0][0]']                \n","                                                                                                  \n"," dropout_28 (Dropout)           (None, 36, 6)        0           ['multi_head_attention_8[0][0]'] \n","                                                                                                  \n"," layer_normalization_18 (LayerN  (None, 36, 6)       12          ['dropout_28[0][0]']             \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.__operators__.add_16 (TFOpL  (None, 36, 6)       0           ['layer_normalization_18[0][0]', \n"," ambda)                                                           'input_5[0][0]']                \n","                                                                                                  \n"," conv1d_42 (Conv1D)             (None, 36, 16)       112         ['tf.__operators__.add_16[0][0]']\n","                                                                                                  \n"," dropout_29 (Dropout)           (None, 36, 16)       0           ['conv1d_42[0][0]']              \n","                                                                                                  \n"," conv1d_43 (Conv1D)             (None, 36, 6)        102         ['dropout_29[0][0]']             \n","                                                                                                  \n"," layer_normalization_19 (LayerN  (None, 36, 6)       12          ['conv1d_43[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.__operators__.add_17 (TFOpL  (None, 36, 6)       0           ['layer_normalization_19[0][0]', \n"," ambda)                                                           'tf.__operators__.add_16[0][0]']\n","                                                                                                  \n"," multi_head_attention_9 (MultiH  (None, 36, 6)       110598      ['tf.__operators__.add_17[0][0]',\n"," eadAttention)                                                    'tf.__operators__.add_17[0][0]']\n","                                                                                                  \n"," dropout_30 (Dropout)           (None, 36, 6)        0           ['multi_head_attention_9[0][0]'] \n","                                                                                                  \n"," layer_normalization_20 (LayerN  (None, 36, 6)       12          ['dropout_30[0][0]']             \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.__operators__.add_18 (TFOpL  (None, 36, 6)       0           ['layer_normalization_20[0][0]', \n"," ambda)                                                           'tf.__operators__.add_17[0][0]']\n","                                                                                                  \n"," conv1d_44 (Conv1D)             (None, 36, 16)       112         ['tf.__operators__.add_18[0][0]']\n","                                                                                                  \n"," dropout_31 (Dropout)           (None, 36, 16)       0           ['conv1d_44[0][0]']              \n","                                                                                                  \n"," conv1d_45 (Conv1D)             (None, 36, 6)        102         ['dropout_31[0][0]']             \n","                                                                                                  \n"," layer_normalization_21 (LayerN  (None, 36, 6)       12          ['conv1d_45[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.__operators__.add_19 (TFOpL  (None, 36, 6)       0           ['layer_normalization_21[0][0]', \n"," ambda)                                                           'tf.__operators__.add_18[0][0]']\n","                                                                                                  \n"," multi_head_attention_10 (Multi  (None, 36, 6)       110598      ['tf.__operators__.add_19[0][0]',\n"," HeadAttention)                                                   'tf.__operators__.add_19[0][0]']\n","                                                                                                  \n"," dropout_32 (Dropout)           (None, 36, 6)        0           ['multi_head_attention_10[0][0]']\n","                                                                                                  \n"," layer_normalization_22 (LayerN  (None, 36, 6)       12          ['dropout_32[0][0]']             \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.__operators__.add_20 (TFOpL  (None, 36, 6)       0           ['layer_normalization_22[0][0]', \n"," ambda)                                                           'tf.__operators__.add_19[0][0]']\n","                                                                                                  \n"," conv1d_46 (Conv1D)             (None, 36, 16)       112         ['tf.__operators__.add_20[0][0]']\n","                                                                                                  \n"," dropout_33 (Dropout)           (None, 36, 16)       0           ['conv1d_46[0][0]']              \n","                                                                                                  \n"," conv1d_47 (Conv1D)             (None, 36, 6)        102         ['dropout_33[0][0]']             \n","                                                                                                  \n"," layer_normalization_23 (LayerN  (None, 36, 6)       12          ['conv1d_47[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.__operators__.add_21 (TFOpL  (None, 36, 6)       0           ['layer_normalization_23[0][0]', \n"," ambda)                                                           'tf.__operators__.add_20[0][0]']\n","                                                                                                  \n"," multi_head_attention_11 (Multi  (None, 36, 6)       110598      ['tf.__operators__.add_21[0][0]',\n"," HeadAttention)                                                   'tf.__operators__.add_21[0][0]']\n","                                                                                                  \n"," dropout_34 (Dropout)           (None, 36, 6)        0           ['multi_head_attention_11[0][0]']\n","                                                                                                  \n"," layer_normalization_24 (LayerN  (None, 36, 6)       12          ['dropout_34[0][0]']             \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.__operators__.add_22 (TFOpL  (None, 36, 6)       0           ['layer_normalization_24[0][0]', \n"," ambda)                                                           'tf.__operators__.add_21[0][0]']\n","                                                                                                  \n"," conv1d_48 (Conv1D)             (None, 36, 16)       112         ['tf.__operators__.add_22[0][0]']\n","                                                                                                  \n"," dropout_35 (Dropout)           (None, 36, 16)       0           ['conv1d_48[0][0]']              \n","                                                                                                  \n"," conv1d_49 (Conv1D)             (None, 36, 6)        102         ['dropout_35[0][0]']             \n","                                                                                                  \n"," layer_normalization_25 (LayerN  (None, 36, 6)       12          ['conv1d_49[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," tf.__operators__.add_23 (TFOpL  (None, 36, 6)       0           ['layer_normalization_25[0][0]', \n"," ambda)                                                           'tf.__operators__.add_22[0][0]']\n","                                                                                                  \n"," global_average_pooling1d_6 (Gl  (None, 36)          0           ['tf.__operators__.add_23[0][0]']\n"," obalAveragePooling1D)                                                                            \n","                                                                                                  \n"," dense_18 (Dense)               (None, 128)          4736        ['global_average_pooling1d_6[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," dropout_36 (Dropout)           (None, 128)          0           ['dense_18[0][0]']               \n","                                                                                                  \n"," dense_19 (Dense)               (None, 12)           1548        ['dropout_36[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 449,628\n","Trainable params: 449,628\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["#@title Build and compile of the Transformer model\n","\n","input_shape = X_train.shape[1:] # shape of the sequence\n","\n","model = build_model(\n","    input_shape,\n","    head_size=256,\n","    num_heads=16,\n","    ff_dim=16,\n","    num_transformer_blocks=4,\n","    mlp_units=[128],\n","    mlp_dropout=0.25,\n","    dropout=0.4,\n",")\n","\n","model.compile(\n","    loss=tfk.losses.CategoricalCrossentropy(),\n","    optimizer=tfk.optimizers.Adam(learning_rate=1e-4),\n","    metrics=[\"accuracy\"],\n",")\n"," \n","# model.summary()"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"8W2-FqbnKjZ0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671811672322,"user_tz":-60,"elapsed":384,"user":{"displayName":"Andrea Cerasani","userId":"02098686880230063779"}},"outputId":"f086f554-340a-4385-e9d2-dc63ff979017"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"1DCNN\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," Input (InputLayer)          [(None, 36, 6)]           0         \n","                                                                 \n"," conv1d_29 (Conv1D)          (None, 36, 256)           4864      \n","                                                                 \n"," layer_normalization_17 (Lay  (None, 36, 256)          512       \n"," erNormalization)                                                \n","                                                                 \n"," max_pooling1d_1 (MaxPooling  (None, 18, 256)          0         \n"," 1D)                                                             \n","                                                                 \n"," conv1d_30 (Conv1D)          (None, 18, 256)           196864    \n","                                                                 \n"," global_average_pooling1d_4   (None, 256)              0         \n"," (GlobalAveragePooling1D)                                        \n","                                                                 \n"," dropout_23 (Dropout)        (None, 256)               0         \n","                                                                 \n"," dense_11 (Dense)            (None, 128)               32896     \n","                                                                 \n"," dropout_24 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_12 (Dense)            (None, 12)                1548      \n","                                                                 \n","=================================================================\n","Total params: 236,684\n","Trainable params: 236,684\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["#@title Build and compile of 1D Conv model\n","\n","input_shape = X_train.shape[1:]\n","\n","conv_model = build_1DCNN(input_shape, nclasses)\n","conv_model.summary()"]},{"cell_type":"code","source":["#@title Build and compile of ResNet model\n","\n","input_shape = X_train.shape[1:] # shape of the build_model(input_shape, nclasses)\n","\n","resnet_model = build_ResNet(input_shape, nclasses)\n","resnet_model.summary()"],"metadata":{"id":"SlHfC0whXBVf","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671811678068,"user_tz":-60,"elapsed":680,"user":{"displayName":"Andrea Cerasani","userId":"02098686880230063779"}},"outputId":"9472817b-56ed-4b1b-c8fe-022a22e4ed5a"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_4 (InputLayer)           [(None, 36, 6)]      0           []                               \n","                                                                                                  \n"," conv1d_31 (Conv1D)             (None, 36, 16)       784         ['input_4[0][0]']                \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 36, 16)      64          ['conv1d_31[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_9 (Activation)      (None, 36, 16)       0           ['batch_normalization_12[0][0]'] \n","                                                                                                  \n"," conv1d_32 (Conv1D)             (None, 36, 16)       1296        ['activation_9[0][0]']           \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 36, 16)      64          ['conv1d_32[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_10 (Activation)     (None, 36, 16)       0           ['batch_normalization_13[0][0]'] \n","                                                                                                  \n"," conv1d_34 (Conv1D)             (None, 36, 16)       112         ['input_4[0][0]']                \n","                                                                                                  \n"," conv1d_33 (Conv1D)             (None, 36, 16)       784         ['activation_10[0][0]']          \n","                                                                                                  \n"," batch_normalization_15 (BatchN  (None, 36, 16)      64          ['conv1d_34[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 36, 16)      64          ['conv1d_33[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_3 (Add)                    (None, 36, 16)       0           ['batch_normalization_15[0][0]', \n","                                                                  'batch_normalization_14[0][0]'] \n","                                                                                                  \n"," activation_11 (Activation)     (None, 36, 16)       0           ['add_3[0][0]']                  \n","                                                                                                  \n"," conv1d_35 (Conv1D)             (None, 36, 32)       4128        ['activation_11[0][0]']          \n","                                                                                                  \n"," batch_normalization_16 (BatchN  (None, 36, 32)      128         ['conv1d_35[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_12 (Activation)     (None, 36, 32)       0           ['batch_normalization_16[0][0]'] \n","                                                                                                  \n"," conv1d_36 (Conv1D)             (None, 36, 32)       5152        ['activation_12[0][0]']          \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 36, 32)      128         ['conv1d_36[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_13 (Activation)     (None, 36, 32)       0           ['batch_normalization_17[0][0]'] \n","                                                                                                  \n"," conv1d_38 (Conv1D)             (None, 36, 32)       544         ['activation_11[0][0]']          \n","                                                                                                  \n"," conv1d_37 (Conv1D)             (None, 36, 32)       3104        ['activation_13[0][0]']          \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 36, 32)      128         ['conv1d_38[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 36, 32)      128         ['conv1d_37[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_4 (Add)                    (None, 36, 32)       0           ['batch_normalization_19[0][0]', \n","                                                                  'batch_normalization_18[0][0]'] \n","                                                                                                  \n"," activation_14 (Activation)     (None, 36, 32)       0           ['add_4[0][0]']                  \n","                                                                                                  \n"," conv1d_39 (Conv1D)             (None, 36, 32)       8224        ['activation_14[0][0]']          \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 36, 32)      128         ['conv1d_39[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_15 (Activation)     (None, 36, 32)       0           ['batch_normalization_20[0][0]'] \n","                                                                                                  \n"," conv1d_40 (Conv1D)             (None, 36, 32)       5152        ['activation_15[0][0]']          \n","                                                                                                  \n"," batch_normalization_21 (BatchN  (None, 36, 32)      128         ['conv1d_40[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_16 (Activation)     (None, 36, 32)       0           ['batch_normalization_21[0][0]'] \n","                                                                                                  \n"," conv1d_41 (Conv1D)             (None, 36, 32)       3104        ['activation_16[0][0]']          \n","                                                                                                  \n"," batch_normalization_23 (BatchN  (None, 36, 32)      128         ['activation_14[0][0]']          \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_22 (BatchN  (None, 36, 32)      128         ['conv1d_41[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," add_5 (Add)                    (None, 36, 32)       0           ['batch_normalization_23[0][0]', \n","                                                                  'batch_normalization_22[0][0]'] \n","                                                                                                  \n"," activation_17 (Activation)     (None, 36, 32)       0           ['add_5[0][0]']                  \n","                                                                                                  \n"," global_average_pooling1d_5 (Gl  (None, 32)          0           ['activation_17[0][0]']          \n"," obalAveragePooling1D)                                                                            \n","                                                                                                  \n"," dense_13 (Dense)               (None, 12)           396         ['global_average_pooling1d_5[0][0\n","                                                                 ]']                              \n","                                                                                                  \n","==================================================================================================\n","Total params: 34,060\n","Trainable params: 33,420\n","Non-trainable params: 640\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["#@title Build and compile of LSTM model\n","\n","input_shape = X_train.shape[1:] # shape of the build_model(input_shape, nclasses)\n","\n","lstm_model = build_LSTM(input_shape, nclasses)\n","lstm_model.summary()"],"metadata":{"id":"RGNqlzMekqeL","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671811682439,"user_tz":-60,"elapsed":737,"user":{"displayName":"Andrea Cerasani","userId":"02098686880230063779"}},"outputId":"538b62d0-8a6d-4046-8efa-bd094cd5e180"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"VanillaLSTM\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," Input (InputLayer)          [(None, 36, 6)]           0         \n","                                                                 \n"," lstm_4 (LSTM)               (None, 36, 256)           269312    \n","                                                                 \n"," lstm_5 (LSTM)               (None, 256)               525312    \n","                                                                 \n"," dropout_25 (Dropout)        (None, 256)               0         \n","                                                                 \n"," dense_14 (Dense)            (None, 128)               32896     \n","                                                                 \n"," dense_15 (Dense)            (None, 12)                1548      \n","                                                                 \n","=================================================================\n","Total params: 829,068\n","Trainable params: 829,068\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["#@title Build and compile of BiLSTM model\n","\n","input_shape = X_train.shape[1:]\n","\n","bilstm_model = build_BiLSTM(input_shape, 4)\n","bilstm_model.summary()"],"metadata":{"id":"ldUdiK5FnDej","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671811686379,"user_tz":-60,"elapsed":1282,"user":{"displayName":"Andrea Cerasani","userId":"02098686880230063779"}},"outputId":"183bc8c9-3067-48ac-e277-52860a3b0fc0","cellView":"form"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"BiLSTM\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," Input (InputLayer)          [(None, 36, 6)]           0         \n","                                                                 \n"," bidirectional_2 (Bidirectio  (None, 36, 184)          72864     \n"," nal)                                                            \n","                                                                 \n"," bidirectional_3 (Bidirectio  (None, 184)              203872    \n"," nal)                                                            \n","                                                                 \n"," dropout_26 (Dropout)        (None, 184)               0         \n","                                                                 \n"," dense_16 (Dense)            (None, 128)               23680     \n","                                                                 \n"," dropout_27 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_17 (Dense)            (None, 4)                 516       \n","                                                                 \n","=================================================================\n","Total params: 300,932\n","Trainable params: 300,932\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["# Training of models"],"metadata":{"id":"T-nzDQXhhpa0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FexLtoXFbkxe"},"outputs":[],"source":["#@title Training of the model\n","callbacks, model_folder_dir = create_folders_and_callbacks(model_name='1DConv')\n","\n","history = conv_model.fit(\n","    x=X_train,\n","    y=y_train,\n","    validation_data=(X_val, y_val),\n","    epochs=200,\n","    batch_size=128,\n","    callbacks=[\n","        callbacks,\n","        tfk.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=5, factor=0.4, min_lr=1e-5)\n","    ]\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SdUcoqwhceLP"},"outputs":[],"source":["#@title Training model and validating using Stratified KFold\n","\n","from sklearn.model_selection import StratifiedKFold\n","\n","callbacks, model_folder_dir = create_folders_and_callbacks(model_name='1DConv')\n","\n","# K-Fold cross validation\n","k = 10\n","skf = StratifiedKFold(n_splits=k)\n","validation_scores = []\n","\n","# store initial model's weights\n","weights_init = model.get_weights()\n","\n","i=0\n","\n","# train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_percentage, shuffle=True, random_state=seed, stratify=to_numerical(y))\n","\n","\n","for train_index, test_index in skf.split(X_train, to_numerical(y_train)):\n","    i += 1\n","    training_data = X_train[train_index]\n","    training_label = y_train[train_index]\n","    validation_data = X_train[test_index]\n","    validation_label = y_train[test_index]\n","\n","    print(\"K = \" + str(i))\n","\n","    # reset mdoel's weights\n","    conv_model = build_1DCNN(input_shape, nclasses)\n","    # fit\n","    conv_model.fit(\n","        training_data, \n","        training_label, \n","        validation_data = (validation_data, validation_label),\n","        epochs=100, \n","        batch_size=64,\n","        callbacks=[\n","          callbacks,\n","          tfk.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=5, factor=0.5, min_lr=1e-5)\n","        ]\n","    )\n","\n","    validation_score = model.evaluate(validation_data, validation_label)[1]\n","    validation_scores.append(validation_score)\n","\n","\n","validation_score = np.average(validation_scores)\n","print(validation_score) "]},{"cell_type":"markdown","source":["# Ensemble"],"metadata":{"id":"GW0xOoRCV5sf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"posYwGZ0U2C6"},"outputs":[],"source":["#@title Training of the 4 classes classifier\n","base_augmenter = (\n","                tsaug.AddNoise(scale=(0.5, 0.8)) @ 0.1\n","                + tsaug.TimeWarp(50) @ 0.3\n","                + tsaug.Pool(size=10) @ 0.3\n","              )\n","\n","callbacks, model_folder_dir = create_folders_and_callbacks(model_name='1DConv')\n","\n","# Selecting only samples from classes 4,5,7,9\n","X_train_4579 = X_train[np.in1d(to_numerical(y_train), [4,5,7,9])]\n","y_train_4579 = y_train[np.in1d(to_numerical(y_train), [4,5,7,9])]\n","X_val_4579 = X_val[np.in1d(to_numerical(y_val), [4,5,7,9])]\n","y_val_4579 = y_val[np.in1d(to_numerical(y_val), [4,5,7,9])]\n","X_test_4579 = X_test[np.in1d(to_numerical(y_test), [4,5,7,9])]\n","y_test_4579 = y_test[np.in1d(to_numerical(y_test), [4,5,7,9])]\n","\n","y_train_4579 = to_numerical(y_train_4579)\n","label_as_binary = LabelBinarizer()\n","y_train_4579 = label_as_binary.fit_transform(y_train_4579)\n","\n","y_val_4579 = to_numerical(y_val_4579)\n","label_as_binary = LabelBinarizer()\n","y_val_4579 = label_as_binary.fit_transform(y_val_4579)\n","\n","y_test_4579 = to_numerical(y_test_4579)\n","label_as_binary = LabelBinarizer()\n","y_test_4579 = label_as_binary.fit_transform(y_test_4579)\n","\n","# Oversampling and augmentation\n","X_train_4579, y_train_4579 = oversample(X_train_4579, y_train_4579)\n","X_train_4579 = base_augmenter.augment(X_train_4579)\n","\n","history = bilstm_model.fit(\n","    x=X_train_4579,\n","    y=y_train_4579,\n","    validation_data=(X_val_4579, y_val_4579),\n","    epochs=200,\n","    batch_size=128,\n","    callbacks=[\n","        callbacks,\n","        tfk.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=5, factor=0.4, min_lr=1e-5)\n","    ]\n",")\n"]},{"cell_type":"code","source":["#@title Prediction using Ensemble\n","predictions = conv_model.predict(X_test)\n","bilstm_predictions = bilstm_model.predict(X_test)\n","\n","ensembled_predictions = np.ndarray(shape=predictions.shape, dtype=float)\n","\n","for i in range(predictions.shape[0]):\n","    predicted_class = np.argmax(predictions[i])\n","    if predicted_class == 9:\n","        bilstm_prediction = bilstm_predictions[i]\n","        complete_bilstm_prediction = [0, 0, 0, 0, bilstm_prediction[0], bilstm_prediction[1], 0, bilstm_prediction[2], 0, bilstm_prediction[3], 0, 0]\n","\n","        ensembled_predictions[i] = complete_bilstm_prediction\n","    else:\n","        ensembled_predictions[i] = predictions[i]\n","        \n","predictions = ensembled_predictions"],"metadata":{"id":"wimavmFYj2uc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Confusion matrix and training trend (with TensorBoard)"],"metadata":{"id":"TjTkl-Fbv8DM"}},{"cell_type":"code","source":["conv_model.evaluate(X_test, y_test, verbose=1)"],"metadata":{"id":"Y_kZM5JD5Q_8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yUUSRuBMKg6k"},"outputs":[],"source":["# Map activities to integers\n","label_mapping = {\n","    0: \"Wish\",\n","    1: \"Another\",\n","    2: \"Comfortably\",\n","    3: \"Money\",\n","    4: \"Breathe\",\n","    5: \"Time\",\n","    6: \"Brain\",\n","    7: \"Echoes\",\n","    8: \"Wearing\",\n","    9: \"Sorrow\",\n","    10: \"Hey\",\n","    11: \"Shine\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sQ7NLv9F57BG"},"outputs":[],"source":["# Predict the test\n","predictions = conv_model.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qs9tQUcl51x6"},"outputs":[],"source":["# Compute the confusion matrix\n","cm = confusion_matrix(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1), normalize=\"true\")\n","\n","# Compute the classification metrics\n","accuracy = accuracy_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1))\n","precision = precision_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n","recall = recall_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n","f1 = f1_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n","print('Accuracy:',accuracy.round(4))\n","print('Precision:',precision.round(4))\n","print('Recall:',recall.round(4))\n","print('F1:',f1.round(4))\n","\n","# Plot the confusion matrix\n","plt.figure(figsize=(10,8))\n","sns.heatmap(cm.T, cmap='Blues', xticklabels=list(label_mapping.keys()), yticklabels=list(label_mapping.keys()), annot=True)\n","plt.xlabel('True labels')\n","plt.ylabel('Predicted labels')\n","plt.show()"]},{"cell_type":"code","source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","import tensorflow as tf\n","import datetime\n","\n","%tensorboard --logdir trained_models/1DConv_12-17_14-15-11/tb_logs\n","\n","import IPython"],"metadata":{"id":"gt-0yg1ILVCJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Save models"],"metadata":{"id":"w7CwZBSkwPt9"}},{"cell_type":"code","source":["evaluation_dict = conv_model.evaluate(X_test, y_test, verbose=1, return_dict=True)"],"metadata":{"id":"qoOcYPsmwWZA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conv_model.save('saved_models/' + conv_model.name + '_' + \"{:.4f}\".format(evaluation_dict['accuracy']))"],"metadata":{"id":"DLi-aCffwiWH"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["01Da5EV2vw8u","WuMeGtEvvpY4","TjTkl-Fbv8DM","w7CwZBSkwPt9"]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}